{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388c64f2",
   "metadata": {
    "height": 46,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script distro is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script openai is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain langchain-openai langchain-anthropic langchain-community wikipedia langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5e618e",
   "metadata": {
    "height": 216,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os \n",
    "import getpass\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\")\n",
    "os.environ['USER_AGENT'] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea6420b",
   "metadata": {
    "height": 301
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an expert extraction algorithm. \"\n",
    "    \"Only extract relevant information from the text. \"\n",
    "    \"If you do not know the value of an attribute asked \"\n",
    "    \"to extract, return null for the attribute's value. \"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        MessagesPlaceholder(\"examples\"),\n",
    "        (\"human\",\"{text}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3b8d0c",
   "metadata": {
    "height": 80
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value. \"), HumanMessage(content='testing 1 2 3'), HumanMessage(content='this is some text')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt.invoke({\"text\" : \"this is some text\",\"examples\" : [HumanMessage(content = \"testing 1 2 3\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bf9b4c6",
   "metadata": {
    "height": 369
   },
   "outputs": [],
   "source": [
    "from typing import List,Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person\"\"\"\n",
    "    name : Optional[str] = Field(..., description = \"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        ...,\n",
    "        description = \"The color of the person's if known\"\n",
    "    )\n",
    "    height_in_meters:Optional[str] = Field(\n",
    "        ...,\n",
    "        description = \"Height in METERs\"\n",
    "    )\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people. \"\"\"\n",
    "    people : List[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b711ff75",
   "metadata": {
    "height": 641
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Dict,List,TypedDict\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Example(TypedDict):\n",
    "    input : str\n",
    "    tool_calls : List[BaseModel]\n",
    "\n",
    "def tool_example_to_messages(example: Example) -> List[BaseMessage]:\n",
    "    messages: List[BaseMessage] = [HumanMessage(content = example[\"input\"])]\n",
    "    tool_calls = []\n",
    "    \n",
    "    for tool_call in example[\"tool_calls\"]:\n",
    "        tool_calls.append(\n",
    "            {\n",
    "                \"id\" : str(uuid.uuid4()),\n",
    "                \"args\" : tool_call.dict(),\n",
    "                \"name\" : tool_call.__class__.__name__\n",
    "            }\n",
    "        )\n",
    "    messages.append(AIMessage(content = \"\",tool_calls = tool_calls))\n",
    "    tool_outputs = example.get(\"tool_outputs\") or [\n",
    "        \"You have correctly called this tool\"\n",
    "    ] * len(tool_calls)\n",
    "    \n",
    "    for output,tool_call in zip(tool_outputs,tool_calls):\n",
    "        messages.append(ToolMessage(content = output,tool_call_id = tool_call[\"id\"]))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123ba9a2",
   "metadata": {
    "height": 318
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\n",
    "        \"This ocean is vast and blue. Its more than 20,000 feet deep. There are many fish in it.\",\n",
    "        Person(name = None, height_in_meters = None, hair_color = None),\n",
    "    ),\n",
    "    (\n",
    "        \"Virat scored at an average of 10.24 in this edition's World Cup.\",\n",
    "        Person(name = \"Virat\", height_in_meters = None, hair_color = None),\n",
    "    )\n",
    "]\n",
    "\n",
    "messages = []\n",
    "\n",
    "for text,tool_call in examples:\n",
    "    messages.extend(\n",
    "        tool_example_to_messages({\"input\" : text,\"tool_calls\" : [tool_call]})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1984ac4e",
   "metadata": {
    "height": 114
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system : content=\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value. \"\n",
      "\n",
      "\n",
      "\n",
      "human : content='This ocean is vast and blue. Its more than 20,000 feet deep. There are many fish in it.'\n",
      "\n",
      "\n",
      "\n",
      "ai : content='' tool_calls=[{'name': 'Person', 'args': {'name': None, 'hair_color': None, 'height_in_meters': None}, 'id': '86ed6ba5-f029-4954-8d4c-5b61ab470e5b'}]\n",
      "\n",
      "\n",
      "\n",
      "tool : content='You have correctly called this tool' tool_call_id='86ed6ba5-f029-4954-8d4c-5b61ab470e5b'\n",
      "\n",
      "\n",
      "\n",
      "human : content=\"Virat scored at an average of 10.24 in this edition's World Cup.\"\n",
      "\n",
      "\n",
      "\n",
      "ai : content='' tool_calls=[{'name': 'Person', 'args': {'name': 'Virat', 'hair_color': None, 'height_in_meters': None}, 'id': 'f68875a1-f004-47f6-8d5f-90cf90f8c84a'}]\n",
      "\n",
      "\n",
      "\n",
      "tool : content='You have correctly called this tool' tool_call_id='f68875a1-f004-47f6-8d5f-90cf90f8c84a'\n",
      "\n",
      "\n",
      "\n",
      "human : content='this is some text'\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_prompt = prompt.invoke({\"text\" : \"this is some text\",\"examples\" : messages})\n",
    "\n",
    "for message in example_prompt.messages :\n",
    "    print(f\"{message.type} : {message}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aca6ae",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
